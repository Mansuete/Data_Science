{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_3.csv')\n",
    "train = pd.read_csv('train_3.csv')\n",
    "\n",
    "test = test.drop(columns=['day_of_month'])\n",
    "train = train.drop(columns=['day_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModels:\n",
    "    def __init__(self, model, data_train, data_dev, params=None):\n",
    "        self.model = model\n",
    "        self.grid_search = None\n",
    "        self.params = params\n",
    "        scaler = MinMaxScaler()\n",
    "        self.X_train = data_train.drop(columns=['forecast_volume'])\n",
    "        self.y_train = data_train.forecast_volume\n",
    "        self.X_dev = data_dev.drop(columns=['forecast_volume'])\n",
    "        self.y_dev = data_dev.forecast_volume\n",
    "        self.X_train = scaler.fit_transform(self.X_train)\n",
    "        self.X_dev = scaler.transform(self.X_dev)\n",
    "        self.pred = None\n",
    "    \n",
    "    def fit_model(self):         \n",
    "        if self.params != None:\n",
    "            cv = KFold(n_splits=5,shuffle=True) \n",
    "            self.grid_search = GridSearchCV(self.model,self.params,cv=cv)\n",
    "            self.grid_search.fit(self.X_train,self.y_train)\n",
    "            self.pred = self.grid_search.predict(self.X_dev)\n",
    "            return self.pred, self.grid_search\n",
    "        else:\n",
    "            self.model.fit(self.X_train,self.y_train)\n",
    "            self.pred = self.model.predict(self.X_dev)    \n",
    "            return self.pred, self.model\n",
    "        \n",
    "    def show_metrics(self):\n",
    "        if type(self.pred) != type(np.array([1,2])):\n",
    "            raise Exception('Firstly fit the model!')\n",
    "        else:\n",
    "            if self.params != None:\n",
    "                print(\"{:<30}{}\".format('MSE score on dev:',mean_squared_error(self.y_dev, self.pred)))\n",
    "                print(\"{:<30}{}\".format('Best params:',self.grid_search.best_params_))\n",
    "            else:\n",
    "                print(\"{:<30}{}\".format('MSE score on dev:',mean_squared_error(self.y_dev, self.pred)))\n",
    "\n",
    "    # Функция взята с офф документации sklearn            \n",
    "    def plot_confusion_matrix(self, normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "        \n",
    "        # Plot non-normalized confusion matrix\n",
    "        plt.figure()\n",
    "        \n",
    "        if type(self.pred) != type(np.array([1,2])):\n",
    "            raise Exception('Firstly fit the model!')\n",
    "        \n",
    "        else:        \n",
    "            cm = confusion_matrix(self.y_dev, self.pred)\n",
    "            np.set_printoptions(precision=2)\n",
    "            classes = ['0', '1']\n",
    "\n",
    "            \"\"\"\n",
    "            This function prints and plots the confusion matrix.\n",
    "            Normalization can be applied by setting `normalize=True`.\n",
    "            \"\"\"\n",
    "            if normalize:\n",
    "                cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                print(\"Normalized confusion matrix\")\n",
    "            else:\n",
    "                print('Confusion matrix, without normalization')\n",
    "\n",
    "            print(cm)\n",
    "\n",
    "            plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "            plt.title(title)\n",
    "            plt.colorbar()\n",
    "            tick_marks = np.arange(len(classes))\n",
    "            plt.xticks(tick_marks, classes, rotation=45)\n",
    "            plt.yticks(tick_marks, classes)\n",
    "\n",
    "            fmt = '.2f' if normalize else 'd'\n",
    "            thresh = cm.max() / 2.\n",
    "            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "                plt.text(j, i, format(cm[i, j], fmt),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "            plt.tight_layout()\n",
    "            plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [{\n",
    "#     'n_estimators':[10,20,40],\n",
    "#     'max_depth':[4,5,8,10],\n",
    "#     'min_samples_leaf':[1,10,25]\n",
    "#     }]\n",
    "# randomforest_model = TestModels(RandomForestRegressor(),train, test, params=param_grid)\n",
    "gradient_model = TestModels(GradientBoostingRegressor(random_state=42,\n",
    "                                                      max_depth=14,\n",
    "                                                      min_samples_leaf=10,\n",
    "                                                      n_estimators=30),train, test, params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.33994076, 0.35801697, 0.32106581, ..., 0.27570879, 0.55154273,\n",
       "        0.31161389]),\n",
       " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='ls', max_depth=14, max_features=None,\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=10,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=30, presort='auto', random_state=42,\n",
       "              subsample=1.0, verbose=0, warm_start=False))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_model.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE score on dev:             7.669691674880589\n"
     ]
    }
   ],
   "source": [
    "gradient_model.show_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
