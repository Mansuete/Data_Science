{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stemming.porter2 import stem\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "\n",
    "def preproccesing_data(df, meta_info):\n",
    "\n",
    "   \n",
    "    df['actors'] = df['actors'].apply(lambda x: ' '.join([i.replace(' ', '_') for i in x]))\n",
    "    df['country'] = df['country'].apply(lambda x: \" \".join(x))\n",
    "    df['director'] = df['director'].apply(lambda x: ' '.join([i.replace(' ', '_') for i in x]))\n",
    "    df['genre'] = df['genre'].apply(lambda x: [\"genre_\" + i for i in x])\n",
    "    df['genre'] = df['genre'].apply(lambda x: \" \".join(x))\n",
    "    df['keywords_whole'] = df['keywords'].apply(lambda x: ' '.join([i.replace(' ', '_') for i in x])) \n",
    "    df['keywords_by_space'] = df['keywords'].apply(lambda x: ' '.join([i for i in x])) \n",
    "    df['soup'] = df['genre'] + ' ' + df['keywords_whole']\n",
    "    df['keywords_stemmed'] = df['keywords'].apply(lambda x: [' '.join([stem(word) for word in sentence.split(\" \")]) for sentence in x])\n",
    "    df['keywords_whole_for_nn'] = df['keywords_stemmed'].apply(lambda x: ' '.join([i.replace(' ', '_') for i in x]))\n",
    "    df['bag_of_words_for_train_nn'] = df['genre'] + ' ' + df['keywords_whole_for_nn']\n",
    "\n",
    "    \n",
    "    df['actors'] = df['actors'].str.lower()\n",
    "    df['country'] = df['country'].str.lower()\n",
    "    df['director'] = df['director'].str.lower()\n",
    "    df['genre'] = df['genre'].str.lower()\n",
    "    df['keywords_whole'] = df['keywords_whole'].str.lower()\n",
    "    df['keywords_by_space'] = df['keywords_by_space'].str.lower()\n",
    "    df['soup'] = df['soup'].str.lower()\n",
    "    df['keywords_stemmed'] = df['keywords_stemmed'].str.lower()\n",
    "    df['keywords_whole_for_nn'] = df['keywords_whole_for_nn'].str.lower()\n",
    "    df['bag_of_words_for_train_nn'] = df['bag_of_words_for_train_nn'].str.lower()\n",
    "    \n",
    "\n",
    "    result = pd.merge(df, meta_info, how='inner', on=['imdbID'])[['long', 'imdbID', 'short', 'ukr','originalTitle', 'year',\n",
    "                                                                  'rated', 'genre', 'country', 'soup','keywords_whole_for_nn','bag_of_words_for_train_nn', 'keywords_by_space', 'keywords_whole', 'director', 'actors']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Hands work\n",
    "    result.loc[result.long == '7236d3c9b9ec81a9b5d06fec1bfcf8b0', 'rated'] = 'PG-13'\n",
    "    result.loc[result.imdbID == 'tt3861390', 'genre'] = 'animation adventure family fantasy'\n",
    "        \n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(meta_info_path, output_path, auth, exclude_list=[]):\n",
    "    \n",
    "    response = requests.get('http://192.168.166.200:8080/statistics/current', headers={'Authorization':auth})\n",
    "    df = pd.DataFrame(response.json())\n",
    "    \n",
    "    df.fillna('', inplace=True)\n",
    "    meta_info = pd.read_excel(meta_info_path)\n",
    "    result = preproccesing_data(df, meta_info)\n",
    "    result.fillna('', inplace=True)\n",
    "    \n",
    "    if exclude_list:\n",
    "        result = result.set_index('long').drop(exclude_list, errors='ignore').reset_index()\n",
    "        \n",
    "    result.to_csv(output_path, index = False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main('C:/Users/a.bratun/PlanetaKino/FilmSimilarity/AllFilmsFrom1CWithImdbId-lastversion14.xlsx', 'prod42.csv','Bearer 1ba0adbc-47d5-4f91-9b7d-2f1ceb038e95',\n",
    "     exclude_list=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('prod41.csv')\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['minion', 'racing', 'superhero', 'disney', 'dragon', 'dancing', 'animal', 'father_son_relationship',\n",
    "       'marvel_comics', 'dc_comics', 'based_on_comic_book', 'world_war_two', 'gangster', 'zombie', 'kitchen', 'sex',\n",
    "       'post_apocalypse', 'female_protagonist', 'shark', 'space_travel', 'space', 'martial_arts', 'survivor', 'shootout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags2 = ['husband_wife_relationship', 'father_son_relationship',\n",
    "       'father_daughter_relationship', 'mother_son_relationship',\n",
    "       'mother_daughter_relationship',\n",
    "       'boyfriend_girlfriend_relationship', 'brother_sister_relationship',\n",
    "       'brother_brother_relationship', 'family_relationships',\n",
    "       'sister_sister_relationship', 'ex_husband_ex_wife_relationship',\n",
    "       'interracial_relationship', 'employer_employee_relationship',\n",
    "       'uncle_nephew_relationship',\n",
    "       'older_man_younger_woman_relationship',\n",
    "       'ex_boyfriend_ex_girlfriend_relationship',\n",
    "       'grandfather_grandson_relationship', 'cousin_cousin_relationship',\n",
    "       'grandmother_granddaughter_relationship',\n",
    "       'aunt_nephew_relationship', 'older_woman_younger_man_relationship',\n",
    "       'teacher_student_relationship', 'uncle_niece_relationship',\n",
    "       'grandfather_granddaughter_relationship',\n",
    "       'aunt_niece_relationship', 'male_female_relationship',\n",
    "       'grandmother_grandson_relationship', 'fiance_fiancee_relationship',\n",
    "       'stepfather_stepdaughter_relationship',\n",
    "       'ex_girlfriend_ex_boyfriend_relationship',\n",
    "       'employee_employer_relationship',\n",
    "       'co_worker_co_worker_relationship',\n",
    "       'father_in_law_daughter_in_law_relationship',\n",
    "       'girlfriend_boyfriend_relationship',\n",
    "       'mother_in_law_daughter_in_law_relationship',\n",
    "       'father_in_law_son_in_law_relationship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from stemming.porter2 import stem\n",
    "\n",
    "import pymssql\n",
    "\n",
    "path_to_your_dir = ''\n",
    "\n",
    "from keras.layers import Input, Embedding, Dot, Reshape, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import random\n",
    "import itertools as it\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def separator(x):\n",
    "    x=x.split(',')\n",
    "    for i in range(len(x)):\n",
    "        x[i]=x[i].strip()\n",
    "    return x[:-1]\n",
    "\n",
    "def SQL_ML()   : \n",
    "    query='''select \n",
    "    cast ([test-MovieList].[MovieId-2] as nvarchar(100) ) as long,\n",
    "    [test-MovieList].imdb as imdb,\n",
    "     STUFF(( select ' ' + GenreRelation.Genre  +',' from GenreRelation where GenreRelation.movieId=[test-MovieList].[movieId-2] and GenreRelation.flag=1 for XML PATH('')),1,1,'') as genres,\n",
    "    STUFF (( select ' ' + [TagRelation].tag  +',' from [TagRelation] where [TagRelation].movieId=[test-MovieList].[movieId-2] and [TagRelation].flag=1 for XML PATH('')),1,1,'') as tags\n",
    "     from\n",
    "    [test-MovieList] \n",
    "    right join GenreRelation on GenreRelation.movieId=[test-MovieList].[movieId-2]\n",
    "    where  GenreRelation.flag=1\n",
    "    group by [test-MovieList].[MovieId-2], [test-MovieList].imdb \n",
    "    '''\n",
    "    query1='SELECT * from [test-MovieList]'\n",
    "    conn = pymssql.connect(\n",
    "        host='10.128.150.49',\n",
    "        user=r'InsertToMovieDB',\n",
    "        password='Pgz%sE9w5SR4',\n",
    "        database='MovieDB', \n",
    "    charset='cp1251')\n",
    "    \n",
    "    df = pd.read_sql(query,conn)\n",
    "    df_movie_list=pd.read_sql(query1,conn)\n",
    "    df=df.fillna('')\n",
    "    df.genres=df.genres.apply(lambda x: separator(x))\n",
    "    df.tags=df.tags.apply(lambda x: separator(x))\n",
    "    return df, df_movie_list\n",
    "\n",
    "\n",
    "def preproccesing_data(df, meta_info, dwh_tags):\n",
    "    \n",
    "    \n",
    "\n",
    "    df = pd.merge(df, dwh_tags, how='inner', on=['imdbID'])\n",
    "    df['actors'] = df['actors'].apply(lambda x: ' '.join([i.replace(' ', '_') for i in x]))\n",
    "    df['country'] = df['country'].apply(lambda x: \" \".join(x))\n",
    "    df['director'] = df['director'].apply(lambda x: ' '.join([i.replace(' ', '_') for i in x]))\n",
    "    df['genre'] = df['genre'].apply(lambda x: [\"genre_\" + i for i in x])\n",
    "    df['genre'] = df['genre'].apply(lambda x: \" \".join(x))\n",
    "    df['keywords_whole'] = df['keywords'].apply(lambda x: ' '.join([i.replace(' ', '_') for i in x])) \n",
    "    df['keywords_by_space'] = df['keywords'].apply(lambda x: ' '.join([i for i in x])) \n",
    "    df['soup'] = df['genre'] + ' ' + df['keywords_whole']\n",
    "    df['keywords_stemmed'] = df['keywords'].apply(lambda x: [' '.join([stem(word) for word in sentence.split(\" \")]) for sentence in x])\n",
    "    df['keywords_whole_for_nn'] = df['keywords_stemmed'].apply(lambda x: ' '.join([i.replace(' ', '_') for i in x]))\n",
    "    df['bag_of_words_for_train_nn'] = df['genre'] + ' ' + df['keywords_whole_for_nn']\n",
    "\n",
    "    \n",
    "    df['actors'] = df['actors'].str.lower()\n",
    "    df['country'] = df['country'].str.lower()\n",
    "    df['director'] = df['director'].str.lower()\n",
    "    df['genre'] = df['genre'].str.lower()\n",
    "    df['keywords_whole'] = df['keywords_whole'].str.lower()\n",
    "    df['keywords_by_space'] = df['keywords_by_space'].str.lower()\n",
    "    df['soup'] = df['soup'].str.lower()\n",
    "    df['keywords_stemmed'] = df['keywords_stemmed'].str.lower()\n",
    "    df['keywords_whole_for_nn'] = df['keywords_whole_for_nn'].str.lower()\n",
    "    df['bag_of_words_for_train_nn'] = df['bag_of_words_for_train_nn'].str.lower()\n",
    "    \n",
    "\n",
    "    result = pd.merge(df, meta_info, how='inner', on=['imdbID'])[['long', 'imdbID', 'short', 'ukr','originalTitle', 'year',\n",
    "                                                                  'rated', 'genre', 'country', 'soup','keywords_whole_for_nn','bag_of_words_for_train_nn', 'keywords_by_space', 'keywords_whole', 'director', 'actors']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Hands work\n",
    "#     result.loc[result.long == '7236d3c9b9ec81a9b5d06fec1bfcf8b0', 'rated'] = 'PG-13'\n",
    "#     result.loc[result.imdbID == 'tt3861390', 'genre'] = 'animation adventure family fantasy'\n",
    "        \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_info_from_imdb(auth):\n",
    "    \n",
    "    response = requests.get('http://192.168.166.200:8080/statistics/current', headers={'Authorization':auth})\n",
    "    df = pd.DataFrame(response.json())\n",
    "    df.fillna('', inplace=True)\n",
    "    df.drop(columns=['genre', 'keywords'], inplace=True)\n",
    "    dwh_tags, meta_info = SQL_ML()\n",
    "    dwh_tags.drop(columns=['long'], inplace=True)\n",
    "    dwh_tags.rename(columns={'imdb':'imdbID', 'genres':'genre', 'tags':'keywords'}, inplace=True)\n",
    "    meta_info.rename(columns={'MovieId':'short', 'MovieNameUkr':'ukr','MovieId-2':'long', 'Now':'now', 'imdb ':'imdbID'}, inplace=True)\n",
    "#     meta_info = pd.read_excel(meta_info_path)\n",
    "    result = preproccesing_data(df, meta_info, dwh_tags)\n",
    "    result.fillna('', inplace=True)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "film_db = get_info_from_imdb('Bearer 1ba0adbc-47d5-4f91-9b7d-2f1ceb038e95')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('http://192.168.166.200:8080/statistics/current', headers={'Authorization':'Bearer 1ba0adbc-47d5-4f91-9b7d-2f1ceb038e95'})\n",
    "df = pd.DataFrame(response.json())\n",
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1049, 23)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
